# 多线程知识点总结



### 创建线程的四种方式

* 继承Thread，重写run()方法
* 实现Runnable接口，实现run()方法。但其实还是要把Runnable接口类赋给Thread初始化来完成。
* 使用FutureTask实现带返回值的线程（任务）
* 使用ExecutorService, Executors线程池。

https://www.cnblogs.com/jinggod/p/8485106.html



### Thread常用方法

* currentThread()。静态，返回当前正在执行的线程对象的引用。注意，当前正在执行的线程其实指的是运行run内容的线程，和它位于哪个定义的Thread子类里没有关系。也就是说我们不能用this来指代当前运行的线程。除非比较简单直接的情况，我们一般很难推断出是哪个线程在工作，所以才有这个方法。https://www.cnblogs.com/tfxz/p/12621490.html
* A.start。实例，将线程由NEW状态，变为RUNNABLE(Ready)状态。start后并不会马上执行run()，因为要等待JVM进行线程调度，等到分配时间片后，才转到RUNNABLE(Running)状态运行。start方法不能多次调用，会出错。https://www.cnblogs.com/jinggod/p/8485143.html
* yield。静态，让当前线程暂停，去执行其他可能执行的线程。yield不改变状态(还是RUNNABLE)，只不过从Running变成了Ready。如果没有其他合适的线程（比如优先级偏低），JVM会继续将原来暂停的线程调度回来，继续Running。这个方法尽量少用，容易出错。https://my.oschina.net/u/3637389/blog/1863057?from=timeline
* sleep。静态，让当前线程睡眠，需要指定时间参数。线程从RUNNABLE(Running)变为TIMED_WAITING(限期等待)。睡眠结束后会回到RUNNABLE(Ready)。
* A.join。实例，让当前线程等待另一个线程执行。可以理解为另一个线程A插队执行。有两种，带时间参数和不带时间参数。前者让当前线程从RUNNABLE(Running) -> WAITING，要等到另一个线程A执行结束后，才回到RUNNABLE(Ready)；后者和前者类似，只不过状态变为TIMED_WAITING。如果时间过长，A提前结束，那就不用继续等了；如果时间过短，A还没结束，则时间结束后，提前回到RUNNABLE(Ready)，至于A是否继续运行，要看JVM的具体调度了。join方法基于Object的wait方法，线程调用A.join时，必须能够拿到线程A对象的锁，如果拿不到它是无法wait的。https://www.iteye.com/blog/uule-1101994



### FutureTask

* 要先实现Callable\<T>接口，并用该接口类对象初始化FutureTask\<T>对象。
* FutureTask实现了RunnableFuture接口，该接口同时继承Runnable和Future。所以我们可以既可以将FutureTask对象当成Runnable直接提交给executor用，也可以当成Future直接get结果或者cancel任务用。
* FutureTask的get方法会产生阻塞，调用的线程需要等提交的任务执行完毕（顺利返回或者抛出异常）。
* FutureTask能够在高并发环境下确保任务只执行一次。
* https://www.cnblogs.com/xiaoxi/p/8303574.html



### 线程组

* 线程组包含多个线程和多个其他线程组，类似于树状结构。
* 线程组构造方法默认会将当前运行线程(new ThreadGroup所在线程)的线程组设置为新的ThreadGroup的父线程组。如果后续new Thread的线程没有明确指定线程组，则会将父线程(new Thread线程所在线程)的线程组设置为当前新Thread的线程组。
* 线程组可设置最大优先级，默认是10。线程优先级默认是5。线程组中的线程优先级不能超过该最大优先级。
* 优先级不能完全决定线程的运行顺序，具体要看操作系统的调度算法。只能说高优先级的先执行可能性更高。
* 线程组可以统一设置异常处理，即自动捕获线程组内成员抛出的异常。



### 线程同步

* 本质是使多个线程按照一定顺序去执行。
* 有下面几种方式：

##### 对象锁

``` java
private static Object lock = new Object();

...
@Override
public void run() {
    synchronized (lock) {
        ...
    }
}
...
```

##### Object.wait()和notify()/notifyAll()

* 实例方法，基于对象锁。有了他们，我们可以让线程自己去控制运行/等待。
* notify()方法会随机叫醒一个正在等待的线程，而notifyAll()会叫醒所有正在等待的线程。
* wait/notify都必须写在synchronized中，否则会出错。调用两者前都必须确保线程先获得了lock。wait会让当前线程释放lock，然后进入等待；notify会唤醒等待中的线程，但当前线程不会释放锁，除非又调用wait或者运行结束自动释放。

##### 信号量

* J.U.C包里有Semaphore类可以直接用。
* 我们也可以用volatile来实现类似的功能。但是要注意以下几点：
  * volatile仅保证了可见性，但没有原子性。不要将volatile用在getAndOperate场合（这种场合不原子，如i++），仅仅set或者get的场景是适合volatile的。
  * 一般为了原子性，我们可以直接用synchronized或者AtomicInteger原子类。
  * volatile的可见性是因为它在读取前/写入后都分别添加了内存屏障，保证能从缓存区获得最新值/将最新值写入缓存区。
* https://www.cnblogs.com/gxjz/p/5726979.html
* https://www.cnblogs.com/studyLog-share/p/5295982.html

##### 管道

* 如可用PipedWriter和PipedReader来完成写和读线程。使用前记得将两个管道connect。
* PipedReader的read方法是“阻塞”的。会让线程处于等待，直到管道中有数据写入。可以稍微了解一下API：https://docs.oracle.com/javase/8/docs/api/java/io/PipedReader.html#read--

##### join

* 前面提到过了，是基于Object.wait方法的。

##### sleep

* sleep和wait都会让当前线程释放CPU资源（因为不再是RUNNABLE(Running)了），但是只有wait会释放对象锁。
* sleep不要求写在synchronized方法或者块中。

##### ThreadLocal

* 线程本地存储，让每个线程可以拥有独立的变量。
* 实际上我们可以将一个类的静态变量用ThreadLocal代替，这样面对不同线程的时候可以表达不同的信息。同时也避免了每个线程内部声明私有变量的冗余和麻烦。



### Java内存模型(JMM)

* Java使用的是共享内存并发模型。
* 内存可见性只针对共享变量，即方法区和堆里的数据。虚拟机栈、本地方法栈和程序计数器这些数据属于线程私有的。
* 线程并不直接和主内存通信，而是借助中间一个叫本地内存的概念。本地内存并非真实存在，一般可以理解为高速缓冲区，它缓存主内存共享变量的副本，是每个线程私有的。而JMM负责控制本地内存和主内存间的通信，并且确保内存可见性。
* 内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。



### 重排序

* 指令重排可以保证串行语义（即单线程部分）一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。
* JMM能够保证单线程下的重排序不影响执行结果，尽管执行顺序不一定有序。
* JMM不能保证所有操作立即可见。也就是说，需要我们自己去正确实现多线程下的同步，可能用到volatile、final和synchronized等关键字。
* JMM不保证对64位的long型和double型变量的写操作具有原子性。因为要分高32位和第32位两次写入。虽然volatile不保证原子性，但是可以保证可见性，即如果在这些变量前添加volatile关键字，可保证线程安全。https://www.cnblogs.com/gxjz/p/5726979.html
* JMM中，临界区内（同步块或同步方法中）的代码可以发生重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏锁的内存语义）



### happens-before（先行发生原则）

* 总是确保先发生的操作A对于后发生的操作B是内存可见的。A和B不一定在同一个线程。
* 实际上由于重排序的优化，JMM可以允许A happens before B下，A和B不一定要严格按顺序执行，只要不会改变程序运行的结果即可。
* 一些常见的规则：
  * 单线程中，前面的语句先于后面的语句。
  * 对同一把锁来说，解锁先于后续（申请）加锁。
  * 对同一个volatile变量的操作，写先于后续读。
  * 线程A的start先于A中的任何操作。
  * 线程A执行B.join()并且成功返回。则B中的任何操作先于A中B.join()返回。
  * 传递性。A先于B，B先于C，则A先于C。



### volatile

* volatile主要有两个功能：保证变量的内存可见性；禁止volatile变量与普通变量重排序，该功能通过内存屏障实现。
* 可见性指的是当一个线程对volatile修饰的变量进行写操作时，JMM会立即把该线程对应的本地内存中的共享变量的值刷新到主内存；当一个线程对volatile修饰的变量进行读操作时，JMM会把立即该线程对应的本地内存置为无效，从主内存中读取共享变量的值。
* volatile只能保证基本的volatile变量读/写是原子性的，并不能保证一系列操作具有原子性。而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大；在性能上，volatile更有优势。
* 内存屏障规则：
  * 在每一个volatile写操作前面插入一个StoreStore屏障。这确保了在进行volatile写之前前面的所有普通的写操作都已经刷新到了内存。即避免前面的普通写和volatile写操作进行重排序。
  * 在每一个volatile写操作后面插入一个StoreLoad屏障。这样可以避免volatile写操作与后面可能存在的volatile读写操作发生重排序。
  * 在每一个volatile读操作后面插入一个LoadLoad屏障。这样可以避免volatile读操作和后面普通的读操作进行重排序。
  * 在每一个volatile读操作后面插入一个LoadStore屏障。这样可以避免volatile读操作和后面普通的写操作进行重排序。
* 另外还有一些规则总结：
  * 当第二个操作volatile写时，不论第一个操作是什么，都不能重排序。这个规则保证了volatile写之前的操作不会被重排到volatile写之后。
  * 当第一个操作为volatile读时，不论第二个操作是什么，都不能重排。这个操作保证了volatile读之后的操作不会被重排到volatile读之前。
  * 当第一个操作为volatile写，第二个操作为volatile读时，不能重排。
* https://blog.csdn.net/onroad0612/article/details/81382032
* https://blog.csdn.net/huyongl1989/article/details/90712393



### synchronized

* 用synchronized时，要搞清楚两个问题：
  * 锁是什么。对代码块同步时，我们需要明确指定锁是什么对象；对方法同步时，如果是实例方法，默认为当前实例 this，如果是静态方法，默认为当前类的Class对象。this只针对同一个对象同步，操作不同对象时不会同步；而Class针对一个类同步，即使不是同一个对象。
  * 临界区是什么。也就是synchronized包含的语句范围，只有这部分才会同步。



### 锁

* 对象有四种锁状态：无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态。级别依次从低到高。
* 随着竞争情况逐渐升级，锁的升级很容易发生；而降级发生的条件很苛刻，但JVM是可以将锁降级的。

##### 无锁

* 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

##### 偏向锁

* 线程A获得锁后，分别在Mark Word和栈帧的锁记录线程ID。
* 然后如果线程A再次请求锁，用CAS操作替换线程ID，那么成功，线程A自动获得该锁。
* 如果是线程B请求锁，CAS替换会失败，则发生竞争，需要升级。
* 一旦升级，要修改Mark Word和A中锁记录的信息，重置为无锁状态。整个过程前后要让A挂起和唤醒。
* 注意偏向锁机制：只在发生竞争时才会释放锁。这有别于其他锁。
* 在Java中，锁的默认状态是偏向锁，也就是说如果状态是无锁，会在下一次访问时按轻量锁去处理。

##### 轻量级锁

* 线程A进入同步块后，如果锁是无锁状态，会拷贝Mark Word到栈帧的Displaced Mark Word中。但我们此时不知道是否存在竞争，需要CAS试图让Mark Word指向线程A自己的锁记录，如果成功，说明当前不存在竞争，只有线程A获得锁；否则，存在竞争，线程A进入自旋（不断重复获取锁的操作，次数有限）
* 如果自旋结束后仍未获取锁，那么线程A就进入阻塞状态，同时锁再度升级。
* 假设当前持有锁的线程B退出同步区，则需要释放锁。此时需要CAS操作试图将Displaced Mark Word中的内容复制回Mark Word，但此时Mark Word已经升级了，所以必然失败。锁释放后，进入阻塞的线程A会被唤醒。另外，如果没有A和B竞争的话，B释放后，锁会重新回到偏向锁状态；如果竞争，就升级到重量级锁状态。
* 需要注意的是，偏向锁和轻量级锁都不是互斥锁。
* https://www.cnblogs.com/jyroy/p/11365935.html

##### 重量级锁

* 简单来说，就是会将所有请求锁的线程放到一个等待队列里。然后当一个锁被释放后，从中挑选一个线程尝试获得锁。但由于sychronized本身是非公平的，所以该线程不一定保证获得锁。
* 当调用一个锁对象的wait或notify方法时，如当前锁的状态是偏向锁或轻量级锁则会先升级胀成重量级锁。
* 重量级锁相比轻量级锁而言需要转换线程的状态，执行效率偏低、更耗时；但好处是不需要自旋，能够节省CPU资源。

##### 锁的升级流程总结

每一个线程在准备获取共享资源时：

第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。

第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空。（撤销偏向锁）

第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的Mark Word的内容修改为自己新建的记录空间的地址的方式竞争Mark Word。

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于轻量级锁的状态，如果自旋失败，进入重量级锁的状态 。

第六步，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。



### 乐观锁和悲观锁

* 悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。
* 乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。乐观锁不存在死锁的问题。

### CAS

* 比较并交换（Compare And Swap）操作，是一种原子操作。

* 过程：判断要更新的变量值，是否等于预期值，如果是，则更新为新值；否则，放弃更新，什么都不做。这里预期值指的是变量原来的值。

* 当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

* Java实现CAS用的是Unsafe类，包含一些 native 方法，需要交给JNI(Java Native Interface)调用其他语言(C/C++)来实现对底层的访问。https://www.cnblogs.com/KingIceMou/p/7239668.html

* AtomicInteger支持对基本类型，数组，对象（引用）等进行原子操作。

* 常见的AtomicInteger类的getAndAdd(int delta)方法也是调用Unsafe类的方法来实现的，核心是一个do-while循环体，并且不断进行CAS操作。

  ``` java
  do {
      v = getIntVolatile(o, offset);	// 预期值
  } while (!weakCompareAndSetInt(o, offset, v, v + delta));	// CAS操作
  ```

* CAS会存在的问题：

  * ABA，即A->B->A，实际上更新了两次，但CAS无法检测出变化。解决方法是给变量添加独特的标记，如版本号或者时间戳。Java里面用的是AtomicStampedReference类来解决。除了预期值要和当前值相等外，预期标记也要和当前标记相等时，才成功进行替换操作。
  * 自旋循环时间长，会占用大量CPU资源。解决方法：用pause指令，自旋失败后CPU小睡一段时间再继续自旋。
  * CAS通常只能确保对一个变量进行原子操作。解决方法：将多个变量封装到一个对象中，利用AtomicReference类保证对象操作是原子的；或者干脆不用CAS，直接用sychronized或者锁。



### AQS

* 抽象队列同步器（AbstractQueuedSynchronizer）。ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。
* AQS内部是一个FIFO的双端队列，队列储存的是拥有线程的Node结点。当然，我们也可以用它实现一个单向的队列。如果是双向的话，会指定head和tail结点，head结点我们是分配给占用资源的线程的，而后面的其他结点都处于等待状态。
* AQS中资源共享模式有两种：
  * 独占模式（Exclusive）：资源是独占的，一次只能一个线程获取。如ReentrantLock。
  * 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。
* 当一个线程尝试去获取资源时，AQS会尝试用tryAcquire方法获取资源，如果失败，则通过addWaiter方法把这个线程插入到等待队列中。需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过自旋CAS的方式保证了操作的线程安全性。然后AQS调用aquireQueued方法去让第二个结点自旋尝试直到获取资源。（因为时先进先出，并且第一个结点是占用资源的一方，所以是第二个结点申请）。不论如何，获取成功后，会调用selfInterrupt方法判断是否需要中断。
* AQS用tryRelease方法释放资源。如果释放成功后，还要去唤醒队列中的一个后继结点。（也就是排在最前面且处于等待状态的结点，比较奇怪的是，源码里是从队列尾部往前遍历去找的，而不是按常理从前往后遍历）
* AQS源码里涉及到LockSupport类的方法，都是静态的。
  * park()，阻塞当前线程。
  * unpark(Thread A)，唤醒指定线程A。
  * https://blog.csdn.net/qq_38293564/article/details/80512758
* 有关AQS部分源码的解析：https://www.cnblogs.com/showing/p/6858410.html



### 中断

* 中断的目的是终止线程的执行，不要将中断混淆为字面上的阻塞或者等待。
* 针对处于Blocked, Timed_waiting或者Waiting状态的线程，调用 A.interrupt()会让线程A抛出InterruptedException异常，从而提前结束。但是不能中断 I/O 阻塞和 synchronized 锁阻塞。
* 针对处于Runnable(Running)的线程，调用 A.interrupt() 时，可以在 A 内部用 interrupted() 检测到中断触发，我们就可以提前结束或者返回。
* 中断结束后线程的状态都是Terminated的。



### 线程池

* Java中的线程池顶层接口是`Executor`接口，`ThreadPoolExecutor`是这个接口的实现类

* 线程池的优点：

  * 控制并发数量。避免因为资源消耗过多，导致服务器崩溃。（因为可以复用，所以不需要大量创建新线程/销毁旧线程）
  * 复用已创建的线程。
  * 对线程做统一管理。

* 构造方法参数：

  * corePoolSize：核心线程数最大值
  * maximumPoolSize：线程总数最大值，即核心线程数 + 非核心线程数
  * keepAliveTime：非核心线程闲置超时时长。也适用于核心线程。
  * unit：上面时长的单位，有毫秒和纳秒。
  * workQueue：阻塞队列，即存放等待执行的任务(Runnable)的队列
  * threadFactory：批量创建线程的工厂，会设置一些参数。
  * handler：拒绝处理策略。

* 四种阻塞队列：

  * LinkedBlockingQueue：基于链表，默认大小是无限大（Integer.MAX_VALUE）
  * ArrayBlockingQueue：基于数组。
  * SynchronousQueue：同步队列。
  * DelayQueue：延迟队列。需在指定延迟时间后，才能从队列获取元素。

* 四种拒绝处理策略：

  * ThreadPoolExecutor.AbortPolicy：默认处理策略。丢弃任务并抛出异常。
  * ThreadPoolExecutor.DiscardPolicy：丢弃任务但不抛出异常。
  * ThreadPoolExecutor.DiscardOldestPolicy：丢弃队首（最旧的）任务，然后重新尝试执行。（如果失败，重复此过程）
  * ThreadPoolExecutor.CallerRunsPolicy：由调用线程处理该任务。就是已经和线程池无关了。

* 线程池的关闭方式：

  * shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务
  * shutdownNow()：立即终止线程池，并尝试中断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务。

* 线程池的处理策略：

	* 线程总数量 < corePoolSize，无论线程是否空闲，都会新建一个核心线程执行任务（让核心线程数量快速达到corePoolSize，在核心线程数量 < corePoolSize时）。**注意，这一步需要获得全局锁。**
  
   * 线程总数量 >= corePoolSize时，新来的线程任务会进入任务队列中等待，然后空闲的核心线程会依次去缓存队列中取任务来执行（体现了**线程复用**）。
    
    * 当缓存队列满了，说明这个时候任务已经多到爆棚，需要一些“临时工”来执行这些任务了。于是会创建非核心线程去执行这个任务。**注意，这一步需要获得全局锁。**
    
   * 缓存队列满了， 且总线程数达到了maximumPoolSize，则会采取上面提到的拒绝策略进行处理。
  
* 线程复用原理：ThreadPoolExecutor在创建线程时，会将线程封装成工作线程worker。如果是核心线程，则会被workQueue.take方法所阻塞，直到拿到Runnable后才能返回。而且由于自旋，会不断调用workQueue请求新的任务，故一般不会结束，也不会被销毁。对于非核心线程，则调用workQueue.poll方法，并受限于超时时长，如果没拿到任务，就会结束并被销毁。

* 四种线程池：

  * newCachedThreadPool。核心线程池大小为0，全部为非核心线程。由于最大线程池大小为MAX，所以几乎不可能触发拒绝策略。阻塞队列为SynchronousQueue。
  * newFixedThreadPool。核心线程池大小 = 最大线程池大小，都是设定值。只有核心线程。由于阻塞队列为LinkedBlockingQueue，所以几乎不可能触发拒绝策略。这就导致线程不易被销毁，会一直阻塞，占用系统资源。
  * newSingleThreadExecutor。其实就是传入参数设为 1 的newFixedThreadPool。
  * newScheduledThreadPool。就是一般的线程池，只不过阻塞队列用DelayedWorkQueue实现，支持周期性的任务执行。
  
* https://www.cnblogs.com/dolphin0520/p/3932921.html
  



### Condition的await()和signal()/signalAll()方法

* 总体来说，和Object的wait、notify/notifyAll方法非常类似。只不过Condition需要基于一个锁来完成。而且后者会更加灵活，功能会更强大。

 ``` java
  private Lock lock = new ReentrantLock();
  private Condition condition = lock.newCondition();
 ```

* Object的wait/notify方法需要配合synchronized以及对象锁完成（synchronized指定的对象锁必须和调用wait/notify方法的是同一个对象）；而Condition不需要synchronized，而是手动在代码块前后添加Lock的 lock() 和 unlock() 来构造出临界区。await/signal方法只能在这块区域中使用。
* 和 wait 一样，await 在进入等待队列后会释放锁和 cpu，当被其他线程唤醒或者超时或中断后都需要重新获取锁，获取锁后才会从 await 方法中退出。await 同样和 wait 一样存在等待返回不代表条件成立的问题，所以也需要主动循环条件判断。个人认为这句话是说，如果我们为了让某一个条件成立从而去等待，那么最好不要用 if 而是用 while 设置条件成立时才跳出循环。因为等待前后条件的状态是可能发生变化的。
* https://www.jianshu.com/p/d90594d5cb80



### 阻塞队列

* BlockingQueue是Java util.concurrent包下重要的数据结构，区别于普通的队列，BlockingQueue提供了线程安全的队列访问方式，并发包下很多高级同步类的实现都是基于BlockingQueue实现的。

* BlockingQueue方法除了有一般队列的offer/poll/peek等方法外，最重要的两个方法是put(e)和take()，分别用于插入和移除元素。特点是如果试图的操作无法立即执行，则一直阻塞或者响应中断。

* 阻塞队列不能插入null。

* 具体实现类：

  * ArrayBlockingQueue。基于数组，大小固定（和数组类似），默认为非公平锁，但可以修改参数。
  * LinkedBlockingQueue。基于链表，默认大小是MAX，也可以指定。
  * DelayQueue。DelayQueue是一个没有大小限制的队列，因此往队列中插入数据的操作（生产者）永远不会被阻塞，而只有获取数据的操作（消费者）才会被阻塞。 
  * PriorityQueue。和DelayQueue一样无界，基于优先级，采用非公平锁。
  * SynchronousQueue。大小为0的特殊队列。因为每次put操作都必须等take/poll操作拿走，否则一直阻塞；而每次take操作都必须等put/offer操作放入元素，否则一直阻塞。所以其实每次操作成功返回后队列的大小始终都是0。

* 对于不设置大小或者大小为MAX的阻塞队列，要注意生产者生产数据的速度绝对不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。

* put原理：

  * 所有执行put操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。
  * 判断阻塞队列是否满了，如果满了，则调用await方法阻塞这个线程，并标记为notFull（生产者）线程，同时释放lock锁,等待被消费者线程唤醒。
  * 如果没有满，则调用enqueue方法将元素put进阻塞队列。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。
  * 唤醒一个标记为notEmpty（消费者）的线程。

* take原理：

  * 所有执行take操作的线程竞争lock锁，拿到了lock锁的线程进入下一步，没有拿到lock锁的线程自旋竞争锁。
  * 判断阻塞队列是否为空，如果是空，则调用await方法阻塞这个线程，并标记为notEmpty（消费者）线程，同时释放lock锁,等待被生产者线程唤醒。
  * 如果没有空，则调用dequeue方法。注意这一步的线程还有一种情况是第二步中阻塞的线程被唤醒且又拿到了lock锁的线程。
  * 唤醒一个标记为notFull（生产者）的线程。

* 阻塞队列一个非常重要的应用就是生产者-消费者问题。可以极大地简化我们的代码，不需要同步，不需要判断等。比如用ArrayBlockingQueue指定初始大小后，producer线程就自旋put就行了；而consumer线程就自旋take即可。但是基本的生产者-消费者我们也要掌握其写法。

  

### 锁

  

  

  

  

  

  

  

  













