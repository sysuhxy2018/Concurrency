# 多线程知识点总结



### 创建线程的四种方式

* 继承Thread，重写run()方法
* 实现Runnable接口，实现run()方法。但其实还是要把Runnable接口类赋给Thread初始化来完成。
* 使用FutureTask实现带返回值的线程（任务）
* 使用ExecutorService, Executors线程池。

https://www.cnblogs.com/jinggod/p/8485106.html



### Thread常用方法

* currentThread()。静态，返回当前正在执行的线程对象的引用。注意，当前正在执行的线程其实指的是运行run内容的线程，和它位于哪个定义的Thread子类里没有关系。也就是说我们不能用this来指代当前运行的线程。除非比较简单直接的情况，我们一般很难推断出是哪个线程在工作，所以才有这个方法。https://www.cnblogs.com/tfxz/p/12621490.html
* A.start。实例，将线程由NEW状态，变为RUNNABLE(Ready)状态。start后并不会马上执行run()，因为要等待JVM进行线程调度，等到分配时间片后，才转到RUNNABLE(Running)状态运行。start方法不能多次调用，会出错。https://www.cnblogs.com/jinggod/p/8485143.html
* yield。静态，让当前线程暂停，去执行其他可能执行的线程。yield不改变状态(还是RUNNABLE)，只不过从Running变成了Ready。如果没有其他合适的线程（比如优先级偏低），JVM会继续将原来暂停的线程调度回来，继续Running。这个方法尽量少用，容易出错。https://my.oschina.net/u/3637389/blog/1863057?from=timeline
* sleep。静态，让当前线程睡眠，需要指定时间参数。线程从RUNNABLE(Running)变为TIMED_WAITING(限期等待)。睡眠结束后会回到RUNNABLE(Ready)。
* A.join。实例，让当前线程等待另一个线程执行。可以理解为另一个线程A插队执行。有两种，带时间参数和不带时间参数。前者让当前线程从RUNNABLE(Running) -> WAITING，要等到另一个线程A执行结束后，才回到RUNNABLE(Ready)；后者和前者类似，只不过状态变为TIMED_WAITING。如果时间过长，A提前结束，那就不用继续等了；如果时间过短，A还没结束，则时间结束后，提前回到RUNNABLE(Ready)，至于A是否继续运行，要看JVM的具体调度了。join方法基于Object的wait方法，线程调用A.join时，必须能够拿到线程A对象的锁，如果拿不到它是无法wait的。https://www.iteye.com/blog/uule-1101994



### FutureTask

* 要先实现Callable\<T>接口，并用该接口类对象初始化FutureTask\<T>对象。
* FutureTask实现了RunnableFuture接口，该接口同时继承Runnable和Future。所以我们可以既可以将FutureTask对象当成Runnable直接提交给executor用，也可以当成Future直接get结果或者cancel任务用。
* FutureTask的get方法会产生阻塞，调用的线程需要等提交的任务执行完毕（顺利返回或者抛出异常）。
* FutureTask能够在高并发环境下确保任务只执行一次。
* https://www.cnblogs.com/xiaoxi/p/8303574.html



### 线程组

* 线程组包含多个线程和多个其他线程组，类似于树状结构。
* 线程组构造方法默认会将当前运行线程(new ThreadGroup所在线程)的线程组设置为新的ThreadGroup的父线程组。如果后续new Thread的线程没有明确指定线程组，则会将父线程(new Thread线程所在线程)的线程组设置为当前新Thread的线程组。
* 线程组可设置最大优先级，默认是10。线程优先级默认是5。线程组中的线程优先级不能超过该最大优先级。
* 优先级不能完全决定线程的运行顺序，具体要看操作系统的调度算法。只能说高优先级的先执行可能性更高。
* 线程组可以统一设置异常处理，即自动捕获线程组内成员抛出的异常。



### 线程同步

* 本质是使多个线程按照一定顺序去执行。
* 有下面几种方式：

##### 对象锁

``` java
private static Object lock = new Object();

...
@Override
public void run() {
    synchronized (lock) {
        ...
    }
}
...
```

##### Object.wait()和notify()/notifyAll()

* 实例方法，基于对象锁。有了他们，我们可以让线程自己去控制运行/等待。
* notify()方法会随机叫醒一个正在等待的线程，而notifyAll()会叫醒所有正在等待的线程。
* wait/notify都必须写在synchronized中，否则会出错。调用两者前都必须确保线程先获得了lock。wait会让当前线程释放lock，然后进入等待；notify会唤醒等待中的线程，但当前线程不会释放锁，除非又调用wait或者运行结束自动释放。

##### 信号量

* J.U.C包里有Semaphore类可以直接用。
* 我们也可以用volatile来实现类似的功能。但是要注意以下几点：
  * volatile仅保证了可见性，但没有原子性。不要将volatile用在getAndOperate场合（这种场合不原子，如i++），仅仅set或者get的场景是适合volatile的。
  * 一般为了原子性，我们可以直接用synchronized或者AtomicInteger原子类。
  * volatile的可见性是因为它在读取前/写入后都分别添加了内存屏障，保证能从缓存区获得最新值/将最新值写入缓存区。
* https://www.cnblogs.com/gxjz/p/5726979.html
* https://www.cnblogs.com/studyLog-share/p/5295982.html

##### 管道

* 如可用PipedWriter和PipedReader来完成写和读线程。使用前记得将两个管道connect。
* PipedReader的read方法是“阻塞”的。会让线程处于等待，直到管道中有数据写入。可以稍微了解一下API：https://docs.oracle.com/javase/8/docs/api/java/io/PipedReader.html#read--

##### join

* 前面提到过了，是基于Object.wait方法的。

##### sleep

* sleep和wait都会让当前线程释放CPU资源（因为不再是RUNNABLE(Running)了），但是只有wait会释放对象锁。
* sleep不要求写在synchronized方法或者块中。

##### ThreadLocal

* 线程本地存储，让每个线程可以拥有独立的变量。
* 实际上我们可以将一个类的静态变量用ThreadLocal代替，这样面对不同线程的时候可以表达不同的信息。同时也避免了每个线程内部声明私有变量的冗余和麻烦。



### Java内存模型(JMM)

* Java使用的是共享内存并发模型。
* 内存可见性只针对共享变量，即方法区和堆里的数据。虚拟机栈、本地方法栈和程序计数器这些数据属于线程私有的。
* 线程并不直接和主内存通信，而是借助中间一个叫本地内存的概念。本地内存并非真实存在，一般可以理解为高速缓冲区，它缓存主内存共享变量的副本，是每个线程私有的。而JMM负责控制本地内存和主内存间的通信，并且确保内存可见性。
* 内存可见性，指的是线程之间的可见性，当一个线程修改了共享变量时，另一个线程可以读取到这个修改后的值。



### 重排序

* 指令重排可以保证串行语义（即单线程部分）一致，但是没有义务保证多线程间的语义也一致。所以在多线程下，指令重排序可能会导致一些问题。
* JMM能够保证单线程下的重排序不影响执行结果，尽管执行顺序不一定有序。
* JMM不能保证所有操作立即可见。也就是说，需要我们自己去正确实现多线程下的同步，可能用到volatile、final和synchronized等关键字。
* JMM不保证对64位的long型和double型变量的写操作具有原子性。因为要分高32位和第32位两次写入。虽然volatile不保证原子性，但是可以保证可见性，即如果在这些变量前添加volatile关键字，可保证线程安全。https://www.cnblogs.com/gxjz/p/5726979.html
* JMM中，临界区内（同步块或同步方法中）的代码可以发生重排序（但不允许临界区内的代码“逃逸”到临界区之外，因为会破坏锁的内存语义）



### happens-before（先行发生原则）

* 总是确保先发生的操作A对于后发生的操作B是内存可见的。A和B不一定在同一个线程。
* 实际上由于重排序的优化，JMM可以允许A happens before B下，A和B不一定要严格按顺序执行，只要不会改变程序运行的结果即可。
* 一些常见的规则：
  * 单线程中，前面的语句先于后面的语句。
  * 对同一把锁来说，解锁先于后续（申请）加锁。
  * 对同一个volatile变量的操作，写先于后续读。
  * 线程A的start先于A中的任何操作。
  * 线程A执行B.join()并且成功返回。则B中的任何操作先于A中B.join()返回。
  * 传递性。A先于B，B先于C，则A先于C。



### volatile

* volatile主要有两个功能：保证变量的内存可见性；禁止volatile变量与普通变量重排序，该功能通过内存屏障实现。
* 可见性指的是当一个线程对volatile修饰的变量进行写操作时，JMM会立即把该线程对应的本地内存中的共享变量的值刷新到主内存；当一个线程对volatile修饰的变量进行读操作时，JMM会把立即该线程对应的本地内存置为无效，从主内存中读取共享变量的值。
* volatile只能保证基本的volatile变量读/写是原子性的，并不能保证一系列操作具有原子性。而锁可以保证整个临界区代码的执行具有原子性。所以在功能上，锁比volatile更强大；在性能上，volatile更有优势。
* 内存屏障规则：
  * 在每一个volatile写操作前面插入一个StoreStore屏障。这确保了在进行volatile写之前前面的所有普通的写操作都已经刷新到了内存。即避免前面的普通写和volatile写操作进行重排序。
  * 在每一个volatile写操作后面插入一个StoreLoad屏障。这样可以避免volatile写操作与后面可能存在的volatile读写操作发生重排序。
  * 在每一个volatile读操作后面插入一个LoadLoad屏障。这样可以避免volatile读操作和后面普通的读操作进行重排序。
  * 在每一个volatile读操作后面插入一个LoadStore屏障。这样可以避免volatile读操作和后面普通的写操作进行重排序。
* 另外还有一些规则总结：
  * 当第二个操作volatile写时，不论第一个操作是什么，都不能重排序。这个规则保证了volatile写之前的操作不会被重排到volatile写之后。
  * 当第一个操作为volatile读时，不论第二个操作是什么，都不能重排。这个操作保证了volatile读之后的操作不会被重排到volatile读之前。
  * 当第一个操作为volatile写，第二个操作为volatile读时，不能重排。
* https://blog.csdn.net/onroad0612/article/details/81382032
* https://blog.csdn.net/huyongl1989/article/details/90712393



### synchronized

* 用synchronized时，要搞清楚两个问题：
  * 锁是什么。对代码块同步时，我们需要明确指定锁是什么对象；对方法同步时，如果是实例方法，默认为当前实例 this，如果是静态方法，默认为当前类的Class对象。this只针对同一个对象同步，操作不同对象时不会同步；而Class针对一个类同步，即使不是同一个对象。
  * 临界区是什么。也就是synchronized包含的语句范围，只有这部分才会同步。



### 锁

* 对象有四种锁状态：无锁状态，偏向锁状态，轻量级锁状态和重量级锁状态。级别依次从低到高。
* 随着竞争情况逐渐升级，锁的升级很容易发生；而降级发生的条件很苛刻，但JVM是可以将锁降级的。

##### 无锁

* 无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。

##### 偏向锁

* 线程A获得锁后，分别在Mark Word和栈帧的锁记录线程ID。
* 然后如果线程A再次请求锁，用CAS操作替换线程ID，那么成功，线程A自动获得该锁。
* 如果是线程B请求锁，CAS替换会失败，则发生竞争，需要升级。
* 一旦升级，要修改Mark Word和A中锁记录的信息，重置为无锁状态。整个过程前后要让A挂起和唤醒。
* 注意偏向锁机制：只在发生竞争时才会释放锁。这有别于其他锁。
* 在Java中，锁的默认状态是偏向锁，也就是说如果状态是无锁，会在下一次访问时按轻量锁去处理。

##### 轻量级锁

* 线程A进入同步块后，如果锁是无锁状态，会拷贝Mark Word到栈帧的Displaced Mark Word中。但我们此时不知道是否存在竞争，需要CAS试图让Mark Word指向线程A自己的锁记录，如果成功，说明当前不存在竞争，只有线程A获得锁；否则，存在竞争，线程A进入自旋（不断重复获取锁的操作，次数有限）
* 如果自旋结束后仍未获取锁，那么线程A就进入阻塞状态，同时锁再度升级。
* 假设当前持有锁的线程B退出同步区，则需要释放锁。此时需要CAS操作试图将Displaced Mark Word中的内容复制回Mark Word，但此时Mark Word已经升级了，所以必然失败。锁释放后，进入阻塞的线程A会被唤醒。另外，如果没有A和B竞争的话，B释放后，锁会重新回到偏向锁状态；如果竞争，就升级到重量级锁状态。
* 需要注意的是，偏向锁和轻量级锁都不是互斥锁。
* https://www.cnblogs.com/jyroy/p/11365935.html

##### 重量级锁

* 简单来说，就是会将所有请求锁的线程放到一个等待队列里。然后当一个锁被释放后，从中挑选一个线程尝试获得锁。但由于sychronized本身是非公平的，所以该线程不一定保证获得锁。
* 当调用一个锁对象的wait或notify方法时，如当前锁的状态是偏向锁或轻量级锁则会先升级胀成重量级锁。
* 重量级锁相比轻量级锁而言需要转换线程的状态，执行效率偏低、更耗时；但好处是不需要自旋，能够节省CPU资源。

##### 锁的升级流程总结

每一个线程在准备获取共享资源时：

第一步，检查MarkWord里面是不是放的自己的ThreadId ,如果是，表示当前线程是处于 “偏向锁” 。

第二步，如果MarkWord不是自己的ThreadId，锁升级，这时候，用CAS来执行切换，新的线程根据MarkWord里面现有的ThreadId，通知之前线程暂停，之前线程将Markword的内容置为空。（撤销偏向锁）

第三步，两个线程都把锁对象的HashCode复制到自己新建的用于存储锁的记录空间，接着开始通过CAS操作， 把锁对象的Mark Word的内容修改为自己新建的记录空间的地址的方式竞争Mark Word。

第四步，第三步中成功执行CAS的获得资源，失败的则进入自旋 。

第五步，自旋的线程在自旋过程中，成功获得资源(即之前获的资源的线程执行完成并释放了共享资源)，则整个状态依然处于轻量级锁的状态，如果自旋失败，进入重量级锁的状态 。

第六步，这个时候，自旋的线程进行阻塞，等待之前线程执行完成并唤醒自己。



### 乐观锁和悲观锁

* 悲观锁就是我们常说的锁。对于悲观锁来说，它总是认为每次访问共享资源时会发生冲突，所以必须对每次数据操作加上锁，以保证临界区的程序同一时间只能有一个线程在执行。
* 乐观锁总是假设对共享资源的访问没有冲突，线程可以不停地执行，无需加锁也无需等待。而一旦多个线程发生冲突，乐观锁通常是使用一种称为CAS的技术来保证线程执行的安全性。乐观锁不存在死锁的问题。

### CAS

* 比较并交换（Compare And Swap）操作，是一种原子操作。

* 过程：判断要更新的变量值，是否等于预期值，如果是，则更新为新值；否则，放弃更新，什么都不做。这里预期值指的是变量原来的值。

* 当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。

* Java实现CAS用的是Unsafe类，包含一些 native 方法，需要交给JNI(Java Native Interface)调用其他语言(C/C++)来实现对底层的访问。https://www.cnblogs.com/KingIceMou/p/7239668.html

* AtomicInteger支持对基本类型，数组，对象（引用）等进行原子操作。

* 常见的AtomicInteger类的getAndAdd(int delta)方法也是调用Unsafe类的方法来实现的，核心是一个do-while循环体，并且不断进行CAS操作。

  ``` java
  do {
      v = getIntVolatile(o, offset);	// 预期值
  } while (!weakCompareAndSetInt(o, offset, v, v + delta));	// CAS操作
  ```

* CAS会存在的问题：

  * ABA，即A->B->A，实际上更新了两次，但CAS无法检测出变化。解决方法是给变量添加独特的标记，如版本号或者时间戳。Java里面用的是AtomicStampedReference类来解决。除了预期值要和当前值相等外，预期标记也要和当前标记相等时，才成功进行替换操作。
  * 自旋循环时间长，会占用大量CPU资源。解决方法：用pause指令，自旋失败后CPU小睡一段时间再继续自旋。
  * CAS通常只能确保对一个变量进行原子操作。解决方法：将多个变量封装到一个对象中，利用AtomicReference类保证对象操作是原子的；或者干脆不用CAS，直接用sychronized或者锁。



### AQS

* 抽象队列同步器（AbstractQueuedSynchronizer）。ReentrantLock，Semaphore，ReentrantReadWriteLock，SynchronousQueue，FutureTask等等皆是基于AQS的。
* AQS内部是一个FIFO的双端队列，队列储存的是拥有线程的Node结点。当然，我们也可以用它实现一个单向的队列。如果是双向的话，会指定head和tail结点，head结点我们是分配给占用资源的线程的，而后面的其他结点都处于等待状态。
* AQS中资源共享模式有两种：
  * 独占模式（Exclusive）：资源是独占的，一次只能一个线程获取。如ReentrantLock。
  * 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定。如Semaphore/CountDownLatch。
* 当一个线程尝试去获取资源时，AQS会尝试用tryAcquire方法获取资源，如果失败，则通过addWaiter方法把这个线程插入到等待队列中。需要注意的是由于AQS中会存在多个线程同时争夺资源的情况，因此肯定会出现多个线程同时插入节点的操作，在这里是通过自旋CAS的方式保证了操作的线程安全性。然后AQS调用aquireQueued方法去让第二个结点自旋尝试直到获取资源。（因为时先进先出，并且第一个结点是占用资源的一方，所以是第二个结点申请）。不论如何，获取成功后，会调用selfInterrupt方法判断是否需要中断。
* AQS用tryRelease方法释放资源。如果释放成功后，还要去唤醒队列中的一个后继结点。（也就是排在最前面且处于等待状态的结点，比较奇怪的是，源码里是从队列尾部往前遍历去找的，而不是按常理从前往后遍历）
* AQS源码里涉及到LockSupport类的方法，都是静态的。
  * park()，阻塞当前线程。
  * unpark(Thread A)，唤醒指定线程A。
* 有关AQS部分源码的解析：https://www.cnblogs.com/showing/p/6858410.html



### 线程池













